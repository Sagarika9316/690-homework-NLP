{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8D85m_ta42T"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import os.path\n",
        "import re\n",
        "import tarfile\n",
        "\n",
        "import smart_open\n",
        "\n",
        "def extract_documents(url='https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz'):\n",
        "    with smart_open.open(url, \"rb\") as file:\n",
        "        with tarfile.open(fileobj=file) as tar:\n",
        "            for member in tar.getmembers():\n",
        "                if member.isfile() and re.search(r'nipstxt/nips\\d+/\\d+\\.txt', member.name):\n",
        "                    member_bytes = tar.extractfile(member).read()\n",
        "                    yield member_bytes.decode('utf-8', errors='replace')\n",
        "\n",
        "docs = list(extract_documents())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(docs))\n",
        "print(docs[0][:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM9ltifDa8RF",
        "outputId": "807e0558-6d56-4212-e10a-b6a9ba91cc0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1740\n",
            "387 \n",
            "Neural Net and Traditional Classifiers  \n",
            "William Y. Huang and Richard P. Lippmann \n",
            "MIT Lincoln Laboratory \n",
            "Lexington, MA 02173, USA \n",
            "Abstract\n",
            "Previous work on nets with continuous-valued inputs led to generative \n",
            "procedures to construct convex decision regions with two-layer percepttons (one hidden \n",
            "layer) and arbitrary decision regions with three-layer percepttons (two hidden layers). \n",
            "Here we demonstrate that two-layer perceptton classifiers trained with back propagation \n",
            "can form both c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the documents.\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "# Split the documents into tokens.\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "for idx in range(len(docs)):\n",
        "    docs[idx] = docs[idx].lower()  # Convert to lowercase.\n",
        "    docs[idx] = tokenizer.tokenize(docs[idx])  # Split into words.\n",
        "\n",
        "# Remove numbers, but not words that contain numbers.\n",
        "docs = [[token for token in doc if not token.isnumeric()] for doc in docs]\n",
        "\n",
        "# Remove words that are only one character.\n",
        "docs = [[token for token in doc if len(token) > 1] for doc in docs]"
      ],
      "metadata": {
        "id": "jCF7sRJVbBZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatize the documents.\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dm00J0w_bkwG",
        "outputId": "1a21c7d5-bba0-4b9c-fef0-d12ce80d15b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rare and common tokens.\n",
        "from gensim.corpora import Dictionary\n",
        "\n",
        "# Create a dictionary representation of the documents.\n",
        "dictionary = Dictionary(docs)\n",
        "\n",
        "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
        "dictionary.filter_extremes(no_below=20, no_above=0.75)"
      ],
      "metadata": {
        "id": "AyEpUOsZcPPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bag-of-words representation of the documents.\n",
        "corpus = [dictionary.doc2bow(doc) for doc in docs]"
      ],
      "metadata": {
        "id": "5P8Qo8n_eN8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of unique tokens: %d' % len(dictionary))\n",
        "print('Number of documents: %d' % len(corpus))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXZ0lGpSeOUq",
        "outputId": "c72e3d0a-f81a-4b87-f578-b1c1cef4671f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique tokens: 6754\n",
            "Number of documents: 1740\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train LDA model.\n",
        "from gensim.models import LdaModel\n",
        "\n",
        "# Set training parameters.\n",
        "num_topics = 10\n",
        "chunksize = 1000\n",
        "passes = 10\n",
        "iterations = 50\n",
        "\n",
        "\n",
        " # Don't evaluate model perplexity, takes too much time.\n",
        "\n",
        "# Make an index to word dictionary.\n",
        "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
        "id2word = dictionary.id2token\n",
        "\n",
        "model = LdaModel(\n",
        "    corpus=corpus,\n",
        "    id2word=id2word,\n",
        "    chunksize=chunksize,\n",
        "    alpha='auto',\n",
        "    eta='auto',\n",
        "    iterations=iterations,\n",
        "    num_topics=num_topics,\n",
        "    passes=passes,\n",
        "\n",
        "\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "toQ1xcC-ebdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_topics = model.top_topics(corpus)\n",
        "\n",
        "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
        "avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
        "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
        "\n",
        "from pprint import pprint\n",
        "pprint(top_topics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NbVK6T7ek8n",
        "outputId": "e99f0d3f-b299-45b3-b1d0-ead7001843d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average topic coherence: -0.9062.\n",
            "[([(0.010398114, 'algorithm'),\n",
            "   (0.007678453, 'bound'),\n",
            "   (0.007675012, 'vector'),\n",
            "   (0.006607112, 'point'),\n",
            "   (0.0065486594, 'let'),\n",
            "   (0.0060697766, 'class'),\n",
            "   (0.0053764535, 'any'),\n",
            "   (0.0053564017, 'theorem'),\n",
            "   (0.0053136796, 'linear'),\n",
            "   (0.0050979364, 'weight'),\n",
            "   (0.0046688165, 'xi'),\n",
            "   (0.0046005356, 'error'),\n",
            "   (0.0043408815, 'probability'),\n",
            "   (0.00415273, 'equation'),\n",
            "   (0.0040320335, 'size'),\n",
            "   (0.004026827, 'following'),\n",
            "   (0.0039799516, 'parameter'),\n",
            "   (0.003856438, 'distribution'),\n",
            "   (0.0038247309, 'approximation'),\n",
            "   (0.0038112951, 'matrix')],\n",
            "  -0.5884014732246655),\n",
            " ([(0.01606943, 'training'),\n",
            "   (0.012552043, 'recognition'),\n",
            "   (0.011280242, 'word'),\n",
            "   (0.010469176, 'speech'),\n",
            "   (0.00990295, 'output'),\n",
            "   (0.0077464166, 'were'),\n",
            "   (0.007657672, 'feature'),\n",
            "   (0.007533429, 'hidden'),\n",
            "   (0.007151039, 'layer'),\n",
            "   (0.006634554, 'classifier'),\n",
            "   (0.0064629903, 'unit'),\n",
            "   (0.006409938, 'performance'),\n",
            "   (0.0062002325, 'class'),\n",
            "   (0.005648344, 'error'),\n",
            "   (0.0056350273, 'trained'),\n",
            "   (0.0055616763, 'context'),\n",
            "   (0.0053751804, 'test'),\n",
            "   (0.005226276, 'sequence'),\n",
            "   (0.005164723, 'character'),\n",
            "   (0.0051384233, 'task')],\n",
            "  -0.753528688789516),\n",
            " ([(0.016868137, 'training'),\n",
            "   (0.01593431, 'error'),\n",
            "   (0.009887965, 'weight'),\n",
            "   (0.007910852, 'method'),\n",
            "   (0.00617622, 'prediction'),\n",
            "   (0.0058604246, 'algorithm'),\n",
            "   (0.0058110226, 'performance'),\n",
            "   (0.0057683755, 'parameter'),\n",
            "   (0.005684583, 'test'),\n",
            "   (0.0056751566, 'unit'),\n",
            "   (0.005606338, 'generalization'),\n",
            "   (0.0050700675, 'output'),\n",
            "   (0.0049692066, 'noise'),\n",
            "   (0.0041464153, 'hidden'),\n",
            "   (0.004080583, 'regression'),\n",
            "   (0.003963256, 'expert'),\n",
            "   (0.0036911438, 'term'),\n",
            "   (0.0036898132, 'gaussian'),\n",
            "   (0.0036242418, 'linear'),\n",
            "   (0.003620619, 'estimate')],\n",
            "  -0.756740633709545),\n",
            " ([(0.015233707, 'visual'),\n",
            "   (0.014115293, 'cell'),\n",
            "   (0.010119082, 'unit'),\n",
            "   (0.009506973, 'field'),\n",
            "   (0.009225829, 'stimulus'),\n",
            "   (0.008758868, 'orientation'),\n",
            "   (0.00862469, 'response'),\n",
            "   (0.007348346, 'spatial'),\n",
            "   (0.007227994, 'direction'),\n",
            "   (0.0069763013, 'map'),\n",
            "   (0.00651161, 'receptive'),\n",
            "   (0.0064972276, 'motion'),\n",
            "   (0.0061233216, 'layer'),\n",
            "   (0.0060703475, 'activity'),\n",
            "   (0.005533293, 'cortex'),\n",
            "   (0.00552813, 'neuron'),\n",
            "   (0.00499169, 'object'),\n",
            "   (0.004821727, 'pattern'),\n",
            "   (0.0046802955, 'image'),\n",
            "   (0.0044844775, 'feature')],\n",
            "  -0.8471372199914855),\n",
            " ([(0.026919676, 'image'),\n",
            "   (0.012612687, 'feature'),\n",
            "   (0.008817249, 'object'),\n",
            "   (0.006884354, 'point'),\n",
            "   (0.006859593, 'distance'),\n",
            "   (0.0067389198, 'face'),\n",
            "   (0.0065261084, 'recognition'),\n",
            "   (0.0062606945, 'algorithm'),\n",
            "   (0.0061831414, 'space'),\n",
            "   (0.005350554, 'vector'),\n",
            "   (0.0048965877, 'cluster'),\n",
            "   (0.00478816, 'method'),\n",
            "   (0.0047719544, 'class'),\n",
            "   (0.0047148624, 'pixel'),\n",
            "   (0.004172711, 'representation'),\n",
            "   (0.0040107556, 'approach'),\n",
            "   (0.003802389, 'clustering'),\n",
            "   (0.0038007249, 'transformation'),\n",
            "   (0.0037177647, 'pattern'),\n",
            "   (0.0037034824, 'dimensional')],\n",
            "  -0.8559946274948327),\n",
            " ([(0.022792492, 'neuron'),\n",
            "   (0.014861025, 'cell'),\n",
            "   (0.010366392, 'spike'),\n",
            "   (0.008564781, 'synaptic'),\n",
            "   (0.007356139, 'response'),\n",
            "   (0.006941224, 'firing'),\n",
            "   (0.006051245, 'rate'),\n",
            "   (0.0057071103, 'activity'),\n",
            "   (0.0056773005, 'stimulus'),\n",
            "   (0.0056587476, 'frequency'),\n",
            "   (0.0055098385, 'pattern'),\n",
            "   (0.0047586537, 'potential'),\n",
            "   (0.004223103, 'synapsis'),\n",
            "   (0.0042040744, 'current'),\n",
            "   (0.00406666, 'signal'),\n",
            "   (0.0038883863, 'channel'),\n",
            "   (0.003770537, 'noise'),\n",
            "   (0.0037545417, 'fig'),\n",
            "   (0.0036194639, 'phase'),\n",
            "   (0.0034652702, 'circuit')],\n",
            "  -0.8901898193687843),\n",
            " ([(0.019636696, 'state'),\n",
            "   (0.0127384, 'algorithm'),\n",
            "   (0.008019535, 'probability'),\n",
            "   (0.0074136867, 'distribution'),\n",
            "   (0.0072939126, 'parameter'),\n",
            "   (0.0061312164, 'action'),\n",
            "   (0.0057749706, 'method'),\n",
            "   (0.0057197814, 'step'),\n",
            "   (0.005711811, 'variable'),\n",
            "   (0.005664442, 'policy'),\n",
            "   (0.005164362, 'mean'),\n",
            "   (0.00447154, 'mixture'),\n",
            "   (0.004457398, 'optimal'),\n",
            "   (0.0044442574, 'likelihood'),\n",
            "   (0.0042765243, 'approach'),\n",
            "   (0.0041777766, 'markov'),\n",
            "   (0.0041427203, 'process'),\n",
            "   (0.004015105, 'reinforcement'),\n",
            "   (0.0038014734, 'em'),\n",
            "   (0.0037868675, 'equation')],\n",
            "  -1.0345412705402968),\n",
            " ([(0.015030366, 'control'),\n",
            "   (0.0079029845, 'position'),\n",
            "   (0.0077046077, 'movement'),\n",
            "   (0.0074127987, 'motion'),\n",
            "   (0.0072984756, 'motor'),\n",
            "   (0.006441563, 'robot'),\n",
            "   (0.006342601, 'field'),\n",
            "   (0.006239076, 'target'),\n",
            "   (0.0062273596, 'output'),\n",
            "   (0.005737056, 'trajectory'),\n",
            "   (0.005662292, 'task'),\n",
            "   (0.0054128557, 'velocity'),\n",
            "   (0.004780844, 'controller'),\n",
            "   (0.004746198, 'eye'),\n",
            "   (0.004690365, 'direction'),\n",
            "   (0.0046016346, 'point'),\n",
            "   (0.004520776, 'hand'),\n",
            "   (0.004393257, 'location'),\n",
            "   (0.0042550494, 'were'),\n",
            "   (0.003786427, 'feedback')],\n",
            "  -1.0351897424028154),\n",
            " ([(0.015431402, 'unit'),\n",
            "   (0.011147948, 'weight'),\n",
            "   (0.010257783, 'output'),\n",
            "   (0.008764212, 'state'),\n",
            "   (0.0080410335, 'memory'),\n",
            "   (0.006916972, 'pattern'),\n",
            "   (0.005254778, 'net'),\n",
            "   (0.005204875, 'neuron'),\n",
            "   (0.0051983017, 'node'),\n",
            "   (0.0049035354, 'layer'),\n",
            "   (0.004673606, 'chip'),\n",
            "   (0.0046514207, 'analog'),\n",
            "   (0.0043861484, 'circuit'),\n",
            "   (0.0042894986, 'connection'),\n",
            "   (0.0042698397, 'hidden'),\n",
            "   (0.0041482784, 'architecture'),\n",
            "   (0.003712414, 'bit'),\n",
            "   (0.003682736, 'recurrent'),\n",
            "   (0.003550465, 'current'),\n",
            "   (0.0034038313, 'activation')],\n",
            "  -1.067428497113334),\n",
            " ([(0.01548555, 'signal'),\n",
            "   (0.0128781805, 'component'),\n",
            "   (0.010350537, 'rule'),\n",
            "   (0.01031856, 'source'),\n",
            "   (0.008584004, 'matrix'),\n",
            "   (0.008558355, 'vector'),\n",
            "   (0.00832615, 'filter'),\n",
            "   (0.0076706195, 'algorithm'),\n",
            "   (0.0073455633, 'analysis'),\n",
            "   (0.007076013, 'noise'),\n",
            "   (0.0062741577, 'independent'),\n",
            "   (0.005658022, 'output'),\n",
            "   (0.0055238567, 'code'),\n",
            "   (0.0055126217, 'linear'),\n",
            "   (0.005066332, 'ica'),\n",
            "   (0.0050454503, 'channel'),\n",
            "   (0.0046144878, 'sound'),\n",
            "   (0.0044731977, 'separation'),\n",
            "   (0.004227195, 'representation'),\n",
            "   (0.0040821964, 'distribution')],\n",
            "  -1.232864207694212)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary.filter_extremes(no_below=20, no_above=0.9)"
      ],
      "metadata": {
        "id": "HflsqqBDla9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [dictionary.doc2bow(doc) for doc in docs]"
      ],
      "metadata": {
        "id": "7F99r40elpVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train LDA model.\n",
        "from gensim.models import LdaModel\n",
        "\n",
        "# Set training parameters.\n",
        "num_topics = 15\n",
        "chunksize = 1000\n",
        "passes = 10\n",
        "iterations = 50\n",
        "\n",
        "\n",
        "# Don't evaluate model perplexity, takes too much time.\n",
        "\n",
        "# Make an index to word dictionary.\n",
        "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
        "id2word = dictionary.id2token\n",
        "\n",
        "model = LdaModel(\n",
        "    corpus=corpus,\n",
        "    id2word=id2word,\n",
        "    chunksize=chunksize,\n",
        "    alpha='auto',\n",
        "    eta='auto',\n",
        "    iterations=iterations,\n",
        "    num_topics=num_topics,\n",
        "    passes=passes,\n",
        "\n",
        "\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "gkr2L0sEkZIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_topics = model.top_topics(corpus)\n",
        "\n",
        "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
        "avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
        "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
        "\n",
        "from pprint import pprint\n",
        "pprint(top_topics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9vGxryNkgWI",
        "outputId": "7cbf4cf3-7de5-4dc7-86ec-eeb2adbcab70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average topic coherence: -0.9218.\n",
            "[([(0.017597258, 'error'),\n",
            "   (0.014259963, 'training'),\n",
            "   (0.010176478, 'method'),\n",
            "   (0.00931773, 'weight'),\n",
            "   (0.008318964, 'parameter'),\n",
            "   (0.0075895134, 'prediction'),\n",
            "   (0.0063006394, 'estimate'),\n",
            "   (0.0061006765, 'gaussian'),\n",
            "   (0.006091857, 'test'),\n",
            "   (0.005965685, 'noise'),\n",
            "   (0.005710339, 'regression'),\n",
            "   (0.0052454197, 'performance'),\n",
            "   (0.005159346, 'variance'),\n",
            "   (0.004944791, 'mean'),\n",
            "   (0.0047239033, 'algorithm'),\n",
            "   (0.0047000386, 'distribution'),\n",
            "   (0.004479941, 'output'),\n",
            "   (0.004474498, 'sample'),\n",
            "   (0.0044667358, 'term'),\n",
            "   (0.0043123015, 'approach')],\n",
            "  -0.5466584554569953),\n",
            " ([(0.010376171, 'bound'),\n",
            "   (0.0099022575, 'weight'),\n",
            "   (0.007791584, 'error'),\n",
            "   (0.007213967, 'theorem'),\n",
            "   (0.0070689702, 'let'),\n",
            "   (0.006289797, 'any'),\n",
            "   (0.006089082, 'size'),\n",
            "   (0.0056120944, 'generalization'),\n",
            "   (0.0054806746, 'threshold'),\n",
            "   (0.0050513525, 'output'),\n",
            "   (0.0049433606, 'theory'),\n",
            "   (0.004880567, 'linear'),\n",
            "   (0.0046321163, 'training'),\n",
            "   (0.0045966026, 'dimension'),\n",
            "   (0.004415966, 'parameter'),\n",
            "   (0.0043549356, 'proof'),\n",
            "   (0.004177091, 'point'),\n",
            "   (0.004074297, 'large'),\n",
            "   (0.004017319, 'probability'),\n",
            "   (0.00400293, 'approximation')],\n",
            "  -0.624825616938251),\n",
            " ([(0.033234738, 'unit'),\n",
            "   (0.016820006, 'hidden'),\n",
            "   (0.014575312, 'layer'),\n",
            "   (0.014538586, 'weight'),\n",
            "   (0.012997427, 'pattern'),\n",
            "   (0.011728796, 'output'),\n",
            "   (0.011337022, 'training'),\n",
            "   (0.0094302, 'vector'),\n",
            "   (0.006924363, 'net'),\n",
            "   (0.0066934247, 'error'),\n",
            "   (0.0065886094, 'algorithm'),\n",
            "   (0.006070466, 'distance'),\n",
            "   (0.0058119264, 'representation'),\n",
            "   (0.0049021337, 'digit'),\n",
            "   (0.0047912286, 'recognition'),\n",
            "   (0.004464298, 'space'),\n",
            "   (0.0044444907, 'were'),\n",
            "   (0.0041542025, 'map'),\n",
            "   (0.0040439395, 'feature'),\n",
            "   (0.0038412649, 'method')],\n",
            "  -0.6320760609435219),\n",
            " ([(0.011367927, 'matrix'),\n",
            "   (0.010128443, 'equation'),\n",
            "   (0.010096915, 'point'),\n",
            "   (0.008765279, 'gradient'),\n",
            "   (0.008665505, 'dynamic'),\n",
            "   (0.006997201, 'linear'),\n",
            "   (0.006866621, 'algorithm'),\n",
            "   (0.0062755966, 'component'),\n",
            "   (0.0062205507, 'vector'),\n",
            "   (0.005465554, 'nonlinear'),\n",
            "   (0.0054311194, 'eq'),\n",
            "   (0.005313157, 'gaussian'),\n",
            "   (0.00530795, 'parameter'),\n",
            "   (0.0051282863, 'noise'),\n",
            "   (0.005066135, 'field'),\n",
            "   (0.0049839946, 'solution'),\n",
            "   (0.0047538397, 'rule'),\n",
            "   (0.004545066, 'signal'),\n",
            "   (0.0045029386, 'method'),\n",
            "   (0.004284776, 'analysis')],\n",
            "  -0.6621541418580088),\n",
            " ([(0.019803518, 'neuron'),\n",
            "   (0.019778583, 'cell'),\n",
            "   (0.008620891, 'spike'),\n",
            "   (0.008509794, 'response'),\n",
            "   (0.007611444, 'stimulus'),\n",
            "   (0.0072944136, 'activity'),\n",
            "   (0.0068218056, 'synaptic'),\n",
            "   (0.0059311767, 'firing'),\n",
            "   (0.005893544, 'pattern'),\n",
            "   (0.0055514527, 'cortex'),\n",
            "   (0.0054082223, 'visual'),\n",
            "   (0.004831612, 'connection'),\n",
            "   (0.0046477746, 'cortical'),\n",
            "   (0.004414418, 'rate'),\n",
            "   (0.0042649936, 'orientation'),\n",
            "   (0.0039575314, 'field'),\n",
            "   (0.0039234757, 'frequency'),\n",
            "   (0.0036799135, 'effect'),\n",
            "   (0.0035434917, 'fig'),\n",
            "   (0.0035301498, 'temporal')],\n",
            "  -0.7895684612871011),\n",
            " ([(0.03748139, 'node'),\n",
            "   (0.011419779, 'layer'),\n",
            "   (0.0108992215, 'training'),\n",
            "   (0.009887271, 'weight'),\n",
            "   (0.009619629, 'level'),\n",
            "   (0.00891471, 'output'),\n",
            "   (0.008495685, 'algorithm'),\n",
            "   (0.007708296, 'propagation'),\n",
            "   (0.006994617, 'classifier'),\n",
            "   (0.006828064, 'error'),\n",
            "   (0.00670865, 'performance'),\n",
            "   (0.0058858315, 'architecture'),\n",
            "   (0.0055284887, 'net'),\n",
            "   (0.0054418524, 'rate'),\n",
            "   (0.0053464896, 'processor'),\n",
            "   (0.0049676527, 'detection'),\n",
            "   (0.004910674, 'unit'),\n",
            "   (0.0047281627, 'back'),\n",
            "   (0.004635806, 'signal'),\n",
            "   (0.0045315893, 'processing')],\n",
            "  -0.7925690898809188),\n",
            " ([(0.011248033, 'task'),\n",
            "   (0.00994902, 'training'),\n",
            "   (0.007872763, 'were'),\n",
            "   (0.0077931643, 'rule'),\n",
            "   (0.0064085573, 'performance'),\n",
            "   (0.0051704394, 'word'),\n",
            "   (0.004630518, 'trained'),\n",
            "   (0.004329008, 'test'),\n",
            "   (0.004105974, 'control'),\n",
            "   (0.0040521175, 'feature'),\n",
            "   (0.003956897, 'human'),\n",
            "   (0.0039183227, 'robot'),\n",
            "   (0.0038686313, 'experiment'),\n",
            "   (0.0036421223, 'table'),\n",
            "   (0.0035960113, 'character'),\n",
            "   (0.003401239, 'representation'),\n",
            "   (0.0031760982, 'output'),\n",
            "   (0.0031117476, 'knowledge'),\n",
            "   (0.0030756702, 'they'),\n",
            "   (0.0030644175, 'rate')],\n",
            "  -0.8375421405056545),\n",
            " ([(0.035666823, 'image'),\n",
            "   (0.017589318, 'object'),\n",
            "   (0.013318319, 'feature'),\n",
            "   (0.010404271, 'visual'),\n",
            "   (0.008241426, 'face'),\n",
            "   (0.006670094, 'recognition'),\n",
            "   (0.0063114217, 'representation'),\n",
            "   (0.0061648986, 'point'),\n",
            "   (0.0060771387, 'pixel'),\n",
            "   (0.006056778, 'position'),\n",
            "   (0.0053834394, 'view'),\n",
            "   (0.0051371926, 'field'),\n",
            "   (0.0051150583, 'map'),\n",
            "   (0.0048841275, 'region'),\n",
            "   (0.00466933, 'vision'),\n",
            "   (0.0043106666, 'local'),\n",
            "   (0.004271241, 'location'),\n",
            "   (0.004231488, 'human'),\n",
            "   (0.0042307335, 'motion'),\n",
            "   (0.0040868116, 'space')],\n",
            "  -0.8924763698924967),\n",
            " ([(0.026609229, 'algorithm'),\n",
            "   (0.01127832, 'vector'),\n",
            "   (0.010732715, 'class'),\n",
            "   (0.006772712, 'space'),\n",
            "   (0.0062078806, 'xi'),\n",
            "   (0.006099444, 'method'),\n",
            "   (0.0058840984, 'tree'),\n",
            "   (0.005875907, 'classifier'),\n",
            "   (0.005801831, 'classification'),\n",
            "   (0.005568497, 'kernel'),\n",
            "   (0.0052433084, 'point'),\n",
            "   (0.004602081, 'matrix'),\n",
            "   (0.004581444, 'training'),\n",
            "   (0.004375964, 'linear'),\n",
            "   (0.0041339328, 'parameter'),\n",
            "   (0.0041257013, 'machine'),\n",
            "   (0.00411457, 'feature'),\n",
            "   (0.0040889033, 'em'),\n",
            "   (0.0040878374, 'loss'),\n",
            "   (0.0040336577, 'support')],\n",
            "  -0.9630813262365848),\n",
            " ([(0.017624788, 'speech'),\n",
            "   (0.014353078, 'recognition'),\n",
            "   (0.012769547, 'mixture'),\n",
            "   (0.0118377, 'training'),\n",
            "   (0.011156683, 'word'),\n",
            "   (0.009649366, 'probability'),\n",
            "   (0.009345321, 'output'),\n",
            "   (0.008786105, 'expert'),\n",
            "   (0.008748796, 'state'),\n",
            "   (0.007607328, 'hmm'),\n",
            "   (0.007163534, 'parameter'),\n",
            "   (0.0068750135, 'context'),\n",
            "   (0.0065728165, 'class'),\n",
            "   (0.005958817, 'speaker'),\n",
            "   (0.005917634, 'hidden'),\n",
            "   (0.0058149383, 'feature'),\n",
            "   (0.0056046695, 'likelihood'),\n",
            "   (0.0054781754, 'sequence'),\n",
            "   (0.0052161785, 'were'),\n",
            "   (0.004734659, 'acoustic')],\n",
            "  -0.977961208968033),\n",
            " ([(0.01954653, 'circuit'),\n",
            "   (0.014516075, 'chip'),\n",
            "   (0.013845398, 'analog'),\n",
            "   (0.012526907, 'output'),\n",
            "   (0.010657337, 'current'),\n",
            "   (0.010650415, 'neuron'),\n",
            "   (0.010100868, 'voltage'),\n",
            "   (0.0073811836, 'signal'),\n",
            "   (0.006677107, 'vlsi'),\n",
            "   (0.005132305, 'implementation'),\n",
            "   (0.004623777, 'channel'),\n",
            "   (0.0045473003, 'frequency'),\n",
            "   (0.004501191, 'weight'),\n",
            "   (0.004488292, 'pulse'),\n",
            "   (0.004122668, 'design'),\n",
            "   (0.004066833, 'processing'),\n",
            "   (0.0039804084, 'transistor'),\n",
            "   (0.0039001934, 'bit'),\n",
            "   (0.0038133205, 'filter'),\n",
            "   (0.003784083, 'digital')],\n",
            "  -1.113294820719281),\n",
            " ([(0.015725486, 'state'),\n",
            "   (0.015003311, 'memory'),\n",
            "   (0.01496633, 'unit'),\n",
            "   (0.009698749, 'pattern'),\n",
            "   (0.008130956, 'output'),\n",
            "   (0.007901273, 'recurrent'),\n",
            "   (0.0071978895, 'sequence'),\n",
            "   (0.006010474, 'attractor'),\n",
            "   (0.0053320145, 'weight'),\n",
            "   (0.005214106, 'net'),\n",
            "   (0.004122517, 'structure'),\n",
            "   (0.0038886578, 'activation'),\n",
            "   (0.0038452584, 'language'),\n",
            "   (0.003824902, 'vector'),\n",
            "   (0.0037773212, 'error'),\n",
            "   (0.0037325427, 'representation'),\n",
            "   (0.003609563, 'string'),\n",
            "   (0.0035511842, 'architecture'),\n",
            "   (0.0035041356, 'symbol'),\n",
            "   (0.0034263486, 'delay')],\n",
            "  -1.131213850598408),\n",
            " ([(0.018774025, 'probability'),\n",
            "   (0.017844865, 'distribution'),\n",
            "   (0.011269089, 'variable'),\n",
            "   (0.009114161, 'state'),\n",
            "   (0.008038647, 'prior'),\n",
            "   (0.0076049394, 'bayesian'),\n",
            "   (0.007460393, 'parameter'),\n",
            "   (0.006319552, 'markov'),\n",
            "   (0.0062755966, 'posterior'),\n",
            "   (0.006183976, 'mean'),\n",
            "   (0.0061710966, 'structure'),\n",
            "   (0.0059560654, 'graph'),\n",
            "   (0.0055853915, 'log'),\n",
            "   (0.0053069866, 'tree'),\n",
            "   (0.0052787894, 'algorithm'),\n",
            "   (0.0052488944, 'likelihood'),\n",
            "   (0.0051660044, 'conditional'),\n",
            "   (0.0046945973, 'belief'),\n",
            "   (0.0046667196, 'sample'),\n",
            "   (0.0046493765, 'inference')],\n",
            "  -1.1338328062448395),\n",
            " ([(0.0329817, 'state'),\n",
            "   (0.016085973, 'action'),\n",
            "   (0.013953169, 'algorithm'),\n",
            "   (0.013902847, 'policy'),\n",
            "   (0.0116908755, 'control'),\n",
            "   (0.010543401, 'reinforcement'),\n",
            "   (0.008823158, 'optimal'),\n",
            "   (0.0078112627, 'step'),\n",
            "   (0.006293441, 'reward'),\n",
            "   (0.006213163, 'controller'),\n",
            "   (0.005399131, 'dynamic'),\n",
            "   (0.0051610293, 'space'),\n",
            "   (0.005105432, 'method'),\n",
            "   (0.00431616, 'decision'),\n",
            "   (0.0042483667, 'process'),\n",
            "   (0.004094457, 'td'),\n",
            "   (0.004064317, 'agent'),\n",
            "   (0.0040353285, 'environment'),\n",
            "   (0.00400887, 'sutton'),\n",
            "   (0.0038844973, 'iteration')],\n",
            "  -1.1671614717855483),\n",
            " ([(0.016257528, 'signal'),\n",
            "   (0.013719466, 'source'),\n",
            "   (0.009527276, 'component'),\n",
            "   (0.009199864, 'stimulus'),\n",
            "   (0.008319514, 'noise'),\n",
            "   (0.007620678, 'direction'),\n",
            "   (0.0072823656, 'frequency'),\n",
            "   (0.0072451155, 'motion'),\n",
            "   (0.0070500784, 'sound'),\n",
            "   (0.006682127, 'were'),\n",
            "   (0.006449664, 'ica'),\n",
            "   (0.006144423, 'response'),\n",
            "   (0.00592465, 'cue'),\n",
            "   (0.005918166, 'independent'),\n",
            "   (0.0055541834, 'separation'),\n",
            "   (0.005457617, 'filter'),\n",
            "   (0.0054038386, 'subject'),\n",
            "   (0.0052471, 'channel'),\n",
            "   (0.0050566974, 'analysis'),\n",
            "   (0.0049434965, 'eeg')],\n",
            "  -1.562609675473219)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "My Interpretation:\n",
        "\n",
        "1) LDA model uses huge time to process\n",
        "\n",
        "2)Hence trying to avoid perplexity at the first case by reducing number of iterations on the worst case,also the default number of iterations are 50\n",
        "\n",
        "3)Topics are chosen as 10,15,20 accordingly with the above set as 0.75,0.9 and 0, the output/interpretation is\n",
        "\n",
        "first case : The text which is related to 10 topics is about -0.84% coherence\n",
        "\n",
        "Second case :  The text which is related to 15 topics is about -0.913%\n",
        "\n",
        "Third case :  The text which is related to 20 topics is about -1.4%\n",
        "\n",
        "Overall I see LDA model helps in picking out most similar text from a corpus.I see for the last one when considering without removal of tokens and reduction of filtering the coherence is almost about -1.4 percent that means the model says the words are mostly relevant to each other."
      ],
      "metadata": {
        "id": "UQO_E9TTtJFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpreting the topics:\n",
        "Example: Algorithm has related worlds such as bound,vector,theorem,class, probability, parameter, distribution {in this context almost the resulted words are related to algorithm except words like any,xi,let these might have decreased the avg of coherence\n",
        "\n",
        "Example 2: words like weight,error,pattern,memory, equation, training,rule,unit, parameter,capacity are also coherent with each other,when LDA model is performed if resulted a coherence of -0.6\n",
        "\n",
        "\n",
        "Example 3: when no words are removed there is less coherence which is resulted like -1.4 which says there is extreme relevance between words"
      ],
      "metadata": {
        "id": "0YuWCqK57zmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary= Dictionary (docs)\n",
        "dictionary.filter_extremes(no_below= 20)"
      ],
      "metadata": {
        "id": "hrxJjdk7-Lmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus =[dictionary.doc2bow(doc) for doc in docs]"
      ],
      "metadata": {
        "id": "4-NJ8TO_-ovP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train LDA model.\n",
        "from gensim.models import LdaModel\n",
        "\n",
        "# Set training parameters.\n",
        "num_topics = 20\n",
        "chunksize = 1000\n",
        "passes = 10\n",
        "iterations = 50\n",
        "\n",
        "\n",
        "# Don't evaluate model perplexity, takes too much time.\n",
        "\n",
        "# Make an index to word dictionary.\n",
        "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
        "id2word = dictionary.id2token\n",
        "\n",
        "model = LdaModel(\n",
        "    corpus=corpus,\n",
        "    id2word=id2word,\n",
        "    chunksize=chunksize,\n",
        "    alpha='auto',\n",
        "    eta='auto',\n",
        "    iterations=iterations,\n",
        "    num_topics=num_topics,\n",
        "    passes=passes,\n",
        "\n",
        "\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "IL_ZBQQB-XdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "top_topics = model.top_topics(corpus)\n",
        "\n",
        "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
        "avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
        "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
        "\n",
        "from pprint import pprint\n",
        "pprint(top_topics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyRyZYMl_YdK",
        "outputId": "45672adc-7542-4878-90d8-33b50bbefe12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average topic coherence: -1.4050.\n",
            "[([(0.03056175, 'neuron'),\n",
            "   (0.026194867, 'cell'),\n",
            "   (0.015978487, 'spike'),\n",
            "   (0.01249003, 'synaptic'),\n",
            "   (0.010713542, 'firing'),\n",
            "   (0.009804561, 'stimulus'),\n",
            "   (0.009459405, 'response'),\n",
            "   (0.0080794925, 'activity'),\n",
            "   (0.00654565, 'potential'),\n",
            "   (0.0058221878, 'synapsis'),\n",
            "   (0.0055375383, 'cortical'),\n",
            "   (0.005433991, 'cortex'),\n",
            "   (0.005346227, 'excitatory'),\n",
            "   (0.005226254, 'frequency'),\n",
            "   (0.004959464, 'connection'),\n",
            "   (0.0047365944, 'membrane'),\n",
            "   (0.004672655, 'inhibitory'),\n",
            "   (0.0045390846, 'fig'),\n",
            "   (0.0041231094, 'neuronal'),\n",
            "   (0.0040308377, 'temporal')],\n",
            "  -0.9188208382305046),\n",
            " ([(0.013537649, 'mixture'),\n",
            "   (0.011154318, 'likelihood'),\n",
            "   (0.01071118, 'gaussian'),\n",
            "   (0.010203601, 'estimate'),\n",
            "   (0.00973361, 'density'),\n",
            "   (0.008463204, 'prior'),\n",
            "   (0.00821127, 'em'),\n",
            "   (0.008192208, 'prediction'),\n",
            "   (0.007912517, 'bayesian'),\n",
            "   (0.0074417773, 'posterior'),\n",
            "   (0.006815681, 'estimation'),\n",
            "   (0.006543996, 'log'),\n",
            "   (0.0061518135, 'variance'),\n",
            "   (0.0059048915, 'sample'),\n",
            "   (0.0055046296, 'noise'),\n",
            "   (0.004814516, 'component'),\n",
            "   (0.0047335, 'conditional'),\n",
            "   (0.004462566, 'maximum'),\n",
            "   (0.0043417206, 'validation'),\n",
            "   (0.0041518705, 'covariance')],\n",
            "  -0.9220338108787691),\n",
            " ([(0.019285845, 'visual'),\n",
            "   (0.017258078, 'motion'),\n",
            "   (0.015112381, 'cell'),\n",
            "   (0.014727574, 'field'),\n",
            "   (0.013923346, 'direction'),\n",
            "   (0.01236276, 'eye'),\n",
            "   (0.011918126, 'response'),\n",
            "   (0.008830463, 'stimulus'),\n",
            "   (0.008589672, 'spatial'),\n",
            "   (0.008255622, 'receptive'),\n",
            "   (0.008235438, 'map'),\n",
            "   (0.0074736546, 'velocity'),\n",
            "   (0.0073830723, 'orientation'),\n",
            "   (0.0071619926, 'activity'),\n",
            "   (0.0062527563, 'position'),\n",
            "   (0.0058939676, 'head'),\n",
            "   (0.0058332793, 'neuron'),\n",
            "   (0.0054065697, 'cortex'),\n",
            "   (0.0053199343, 'center'),\n",
            "   (0.0050722403, 'location')],\n",
            "  -1.0158875977703632),\n",
            " ([(0.050211478, 'layer'),\n",
            "   (0.03274903, 'hidden'),\n",
            "   (0.019400274, 'net'),\n",
            "   (0.013486096, 'propagation'),\n",
            "   (0.011942166, 'connection'),\n",
            "   (0.011738549, 'back'),\n",
            "   (0.010405121, 'node'),\n",
            "   (0.010330872, 'map'),\n",
            "   (0.009284457, 'architecture'),\n",
            "   (0.008353381, 'activation'),\n",
            "   (0.0062937345, 'trained'),\n",
            "   (0.0058177584, 'parallel'),\n",
            "   (0.0057385997, 'internal'),\n",
            "   (0.0047988817, 'bp'),\n",
            "   (0.0047930027, 'self'),\n",
            "   (0.00428424, 'target'),\n",
            "   (0.0041769794, 'simulation'),\n",
            "   (0.0040821554, 'field'),\n",
            "   (0.003959981, 'flow'),\n",
            "   (0.0037915497, 'neuron')],\n",
            "  -1.1591039200478537),\n",
            " ([(0.010977655, 'robot'),\n",
            "   (0.009292125, 'reinforcement'),\n",
            "   (0.008454903, 'control'),\n",
            "   (0.007936035, 'action'),\n",
            "   (0.0071542347, 'goal'),\n",
            "   (0.0058247074, 'trial'),\n",
            "   (0.005014194, 'learn'),\n",
            "   (0.0044691996, 'environment'),\n",
            "   (0.0044415058, 'game'),\n",
            "   (0.004408897, 'move'),\n",
            "   (0.0042499932, 'td'),\n",
            "   (0.0042052194, 'cost'),\n",
            "   (0.0041299188, 'position'),\n",
            "   (0.0039793174, 'optimal'),\n",
            "   (0.0039329687, 'search'),\n",
            "   (0.0038923488, 'learned'),\n",
            "   (0.0038721864, 'controller'),\n",
            "   (0.0038043868, 'grid'),\n",
            "   (0.0036906952, 'dynamic'),\n",
            "   (0.003591289, 'world')],\n",
            "  -1.1844523748017368),\n",
            " ([(0.012893994, 'kernel'),\n",
            "   (0.011757322, 'cluster'),\n",
            "   (0.00931984, 'regression'),\n",
            "   (0.0078118513, 'clustering'),\n",
            "   (0.006928877, 'energy'),\n",
            "   (0.0062370542, 'solution'),\n",
            "   (0.0060713505, 'xi'),\n",
            "   (0.0056980466, 'procedure'),\n",
            "   (0.0055435123, 'optimization'),\n",
            "   (0.0048816265, 'selection'),\n",
            "   (0.004740573, 'sample'),\n",
            "   (0.0046519632, 'sampling'),\n",
            "   (0.004558641, 'machine'),\n",
            "   (0.0039777765, 'approximation'),\n",
            "   (0.0034271267, 'support'),\n",
            "   (0.0034263246, 'dimensional'),\n",
            "   (0.0033845764, 'gaussian'),\n",
            "   (0.0032541568, 'evidence'),\n",
            "   (0.0032506697, 'annealing'),\n",
            "   (0.003213202, 'minimum')],\n",
            "  -1.1935177106788295),\n",
            " ([(0.021266473, 'circuit'),\n",
            "   (0.018068863, 'chip'),\n",
            "   (0.015168129, 'analog'),\n",
            "   (0.012851283, 'signal'),\n",
            "   (0.011813075, 'voltage'),\n",
            "   (0.010164197, 'neuron'),\n",
            "   (0.008297133, 'vlsi'),\n",
            "   (0.006749121, 'implementation'),\n",
            "   (0.006207616, 'filter'),\n",
            "   (0.005657278, 'pulse'),\n",
            "   (0.005277942, 'frequency'),\n",
            "   (0.005169448, 'design'),\n",
            "   (0.005081875, 'channel'),\n",
            "   (0.004965688, 'transistor'),\n",
            "   (0.0049499874, 'digital'),\n",
            "   (0.0047921366, 'bit'),\n",
            "   (0.0047901, 'hardware'),\n",
            "   (0.004542237, 'block'),\n",
            "   (0.004330375, 'device'),\n",
            "   (0.0042632995, 'processor')],\n",
            "  -1.2407063274239756),\n",
            " ([(0.019246139, 'action'),\n",
            "   (0.019160427, 'policy'),\n",
            "   (0.011348039, 'optimal'),\n",
            "   (0.009551193, 'reward'),\n",
            "   (0.008691404, 'reinforcement'),\n",
            "   (0.0076011773, 'markov'),\n",
            "   (0.006322816, 'convergence'),\n",
            "   (0.006071822, 'stochastic'),\n",
            "   (0.0054560094, 'decision'),\n",
            "   (0.005432306, 'control'),\n",
            "   (0.0054292735, 'environment'),\n",
            "   (0.0053812615, 'transition'),\n",
            "   (0.0053535243, 'approximation'),\n",
            "   (0.0053245556, 'dynamic'),\n",
            "   (0.005165668, 'rl'),\n",
            "   (0.00514571, 'call'),\n",
            "   (0.0046149446, 'iteration'),\n",
            "   (0.004438323, 'agent'),\n",
            "   (0.004421146, 'update'),\n",
            "   (0.0042047035, 'mdp')],\n",
            "  -1.2644266648896378),\n",
            " ([(0.029957687, 'image'),\n",
            "   (0.016928758, 'object'),\n",
            "   (0.00972696, 'visual'),\n",
            "   (0.006837966, 'filter'),\n",
            "   (0.0068370104, 'pixel'),\n",
            "   (0.006662364, 'sound'),\n",
            "   (0.0066341637, 'scene'),\n",
            "   (0.006375847, 'region'),\n",
            "   (0.0058799256, 'human'),\n",
            "   (0.0056774453, 'scale'),\n",
            "   (0.005236271, 'frequency'),\n",
            "   (0.005187103, 'orientation'),\n",
            "   (0.0050284085, 'contour'),\n",
            "   (0.004852379, 'cue'),\n",
            "   (0.004686303, 'shape'),\n",
            "   (0.0046015168, 'vision'),\n",
            "   (0.0043498343, 'texture'),\n",
            "   (0.0043488047, 'subject'),\n",
            "   (0.0043262863, 'response'),\n",
            "   (0.0041093477, 'location')],\n",
            "  -1.3219756077824887),\n",
            " ([(0.033306822, 'control'),\n",
            "   (0.018167641, 'trajectory'),\n",
            "   (0.015502932, 'motor'),\n",
            "   (0.013259539, 'dynamic'),\n",
            "   (0.011912547, 'controller'),\n",
            "   (0.010961471, 'movement'),\n",
            "   (0.009704207, 'forward'),\n",
            "   (0.009082649, 'feedback'),\n",
            "   (0.00822682, 'arm'),\n",
            "   (0.00746847, 'hand'),\n",
            "   (0.007176168, 'nonlinear'),\n",
            "   (0.007162298, 'position'),\n",
            "   (0.0063463286, 'inverse'),\n",
            "   (0.0061044227, 'desired'),\n",
            "   (0.00603841, 'command'),\n",
            "   (0.0059899157, 'signal'),\n",
            "   (0.0056020413, 'force'),\n",
            "   (0.005131216, 'adaptive'),\n",
            "   (0.005002091, 'joint'),\n",
            "   (0.0045734625, 'muscle')],\n",
            "  -1.3387051867488884),\n",
            " ([(0.022026693, 'class'),\n",
            "   (0.018757485, 'classifier'),\n",
            "   (0.016120873, 'bound'),\n",
            "   (0.010201633, 'classification'),\n",
            "   (0.009799996, 'sample'),\n",
            "   (0.009506491, 'let'),\n",
            "   (0.009476547, 'loss'),\n",
            "   (0.0077461884, 'theorem'),\n",
            "   (0.007607503, 'dimension'),\n",
            "   (0.006088118, 'decision'),\n",
            "   (0.005766811, 'margin'),\n",
            "   (0.0053077387, 'generalization'),\n",
            "   (0.005281058, 'vc'),\n",
            "   (0.0052489536, 'xi'),\n",
            "   (0.005099372, 'complexity'),\n",
            "   (0.004511943, 'svm'),\n",
            "   (0.0042458987, 'risk'),\n",
            "   (0.0039249263, 'optimal'),\n",
            "   (0.003898988, 'log'),\n",
            "   (0.0038059738, 'proof')],\n",
            "  -1.4172107806518217),\n",
            " ([(0.021533215, 'word'),\n",
            "   (0.018141132, 'speech'),\n",
            "   (0.016640576, 'recognition'),\n",
            "   (0.0149096465, 'sequence'),\n",
            "   (0.010104755, 'context'),\n",
            "   (0.009188586, 'rule'),\n",
            "   (0.008450486, 'hmm'),\n",
            "   (0.008026309, 'hidden'),\n",
            "   (0.006674257, 'language'),\n",
            "   (0.006414703, 'speaker'),\n",
            "   (0.0054860692, 'trained'),\n",
            "   (0.005006396, 'class'),\n",
            "   (0.004952846, 'markov'),\n",
            "   (0.004746539, 'phoneme'),\n",
            "   (0.0046314155, 'letter'),\n",
            "   (0.0045626997, 'frame'),\n",
            "   (0.0042985533, 'architecture'),\n",
            "   (0.004229565, 'acoustic'),\n",
            "   (0.004146248, 'string'),\n",
            "   (0.0036745847, 'hmms')],\n",
            "  -1.4208062665756607),\n",
            " ([(0.016720494, 'neuron'),\n",
            "   (0.011482475, 'threshold'),\n",
            "   (0.008572879, 'net'),\n",
            "   (0.007800871, 'activation'),\n",
            "   (0.0073346077, 'theorem'),\n",
            "   (0.006943638, 'gate'),\n",
            "   (0.0060441103, 'proof'),\n",
            "   (0.00583986, 'let'),\n",
            "   (0.005759835, 'computational'),\n",
            "   (0.005221822, 'polynomial'),\n",
            "   (0.0052110897, 'finite'),\n",
            "   (0.0047410633, 'circuit'),\n",
            "   (0.0047069616, 'recurrent'),\n",
            "   (0.0046568154, 'analog'),\n",
            "   (0.0045927158, 'layer'),\n",
            "   (0.004063033, 'element'),\n",
            "   (0.004028913, 'hopfield'),\n",
            "   (0.0040210644, 'connection'),\n",
            "   (0.003965784, 'automaton'),\n",
            "   (0.0039042463, 'capacity')],\n",
            "  -1.491135036536449),\n",
            " ([(0.017413775, 'attractor'),\n",
            "   (0.01674082, 'phase'),\n",
            "   (0.015481034, 'dynamic'),\n",
            "   (0.01306107, 'delay'),\n",
            "   (0.012190868, 'memory'),\n",
            "   (0.011722844, 'module'),\n",
            "   (0.010722754, 'oscillator'),\n",
            "   (0.007625882, 'activity'),\n",
            "   (0.0072576753, 'recurrent'),\n",
            "   (0.007090361, 'oscillation'),\n",
            "   (0.006282317, 'connection'),\n",
            "   (0.0062642917, 'cycle'),\n",
            "   (0.0059467293, 'behavior'),\n",
            "   (0.0058239605, 'frequency'),\n",
            "   (0.0051450287, 'item'),\n",
            "   (0.005047872, 'oscillatory'),\n",
            "   (0.004858724, 'bifurcation'),\n",
            "   (0.0048039183, 'coupling'),\n",
            "   (0.0042676395, 'transition'),\n",
            "   (0.0041736187, 'stable')],\n",
            "  -1.6136893674438941),\n",
            " ([(0.019224444, 'distance'),\n",
            "   (0.01858905, 'memory'),\n",
            "   (0.015983278, 'recognition'),\n",
            "   (0.013645087, 'image'),\n",
            "   (0.013216702, 'character'),\n",
            "   (0.01315626, 'digit'),\n",
            "   (0.009697919, 'transformation'),\n",
            "   (0.00851857, 'classification'),\n",
            "   (0.007797958, 'tangent'),\n",
            "   (0.006692203, 'rotation'),\n",
            "   (0.006167173, 'pixel'),\n",
            "   (0.00509652, 'handwritten'),\n",
            "   (0.0050471006, 'nearest'),\n",
            "   (0.004945621, 'invariance'),\n",
            "   (0.004713298, 'associative'),\n",
            "   (0.004702536, 'class'),\n",
            "   (0.0043895487, 'prototype'),\n",
            "   (0.004076084, 'translation'),\n",
            "   (0.003969967, 'capacity'),\n",
            "   (0.0038640043, 'neighbor')],\n",
            "  -1.6264181975012577),\n",
            " ([(0.023614729, 'expert'),\n",
            "   (0.01780699, 'matrix'),\n",
            "   (0.017230699, 'gradient'),\n",
            "   (0.008972051, 'component'),\n",
            "   (0.008478815, 'descent'),\n",
            "   (0.0063765394, 'pca'),\n",
            "   (0.0062317057, 'rule'),\n",
            "   (0.006212477, 'principal'),\n",
            "   (0.005966183, 'gating'),\n",
            "   (0.005923454, 'eigenvalue'),\n",
            "   (0.005725032, 'pruning'),\n",
            "   (0.005623499, 'architecture'),\n",
            "   (0.0052654822, 'net'),\n",
            "   (0.00510496, 'ob'),\n",
            "   (0.004674228, 'perturbation'),\n",
            "   (0.004591345, 'mixture'),\n",
            "   (0.00417303, 'derivative'),\n",
            "   (0.0040112836, 'backpropagation'),\n",
            "   (0.0039759413, 'optimal'),\n",
            "   (0.0037794393, 'jacob')],\n",
            "  -1.6652584559813237),\n",
            " ([(0.012395121, 'noise'),\n",
            "   (0.009524816, 'matrix'),\n",
            "   (0.008620214, 'signal'),\n",
            "   (0.007762766, 'source'),\n",
            "   (0.006939274, 'component'),\n",
            "   (0.006707395, 'field'),\n",
            "   (0.006650228, 'gaussian'),\n",
            "   (0.0065530017, 'eq'),\n",
            "   (0.00642186, 'independent'),\n",
            "   (0.005787718, 'rule'),\n",
            "   (0.005563017, 'approximation'),\n",
            "   (0.0050590923, 'gradient'),\n",
            "   (0.004970012, 'generalization'),\n",
            "   (0.0048376904, 'optimal'),\n",
            "   (0.00475403, 'solution'),\n",
            "   (0.0044273296, 'entropy'),\n",
            "   (0.004189218, 'ica'),\n",
            "   (0.0040286137, 'student'),\n",
            "   (0.0038180468, 'dynamic'),\n",
            "   (0.0038135939, 'teacher')],\n",
            "  -1.700787795291004),\n",
            " ([(0.023406845, 'tree'),\n",
            "   (0.021898886, 'node'),\n",
            "   (0.0066623813, 'machine'),\n",
            "   (0.0065749697, 'instance'),\n",
            "   (0.0060846535, 'hypothesis'),\n",
            "   (0.005521697, 'class'),\n",
            "   (0.0055215196, 'concept'),\n",
            "   (0.0053383056, 'decision'),\n",
            "   (0.004477545, 'xi'),\n",
            "   (0.0040894994, 'rule'),\n",
            "   (0.003976844, 'graph'),\n",
            "   (0.0038632299, 'domain'),\n",
            "   (0.0037950356, 'belief'),\n",
            "   (0.0036670717, 'support'),\n",
            "   (0.0036663425, 'leaf'),\n",
            "   (0.003529735, 'search'),\n",
            "   (0.0035054502, 'table'),\n",
            "   (0.0034960336, 'boosting'),\n",
            "   (0.0032357275, 'label'),\n",
            "   (0.003230012, 'labeled')],\n",
            "  -1.747921613271396),\n",
            " ([(0.03617677, 'image'),\n",
            "   (0.018238185, 'face'),\n",
            "   (0.013176685, 'basis'),\n",
            "   (0.009987239, 'view'),\n",
            "   (0.009547533, 'recognition'),\n",
            "   (0.009543182, 'object'),\n",
            "   (0.0062915934, 'wavelet'),\n",
            "   (0.006130478, 'dimensional'),\n",
            "   (0.0059187897, 'coefficient'),\n",
            "   (0.00573946, 'similarity'),\n",
            "   (0.0053493157, 'latent'),\n",
            "   (0.0050195395, 'pca'),\n",
            "   (0.0047096913, 'projection'),\n",
            "   (0.004376479, 'manifold'),\n",
            "   (0.00430012, 'component'),\n",
            "   (0.0042354017, 'gaussian'),\n",
            "   (0.0042352807, 'mapping'),\n",
            "   (0.0040963194, 'principal'),\n",
            "   (0.003988451, 'facial'),\n",
            "   (0.0038563213, '2d')],\n",
            "  -1.8884015170565571),\n",
            " ([(0.020045206, 'code'),\n",
            "   (0.01507242, 'graph'),\n",
            "   (0.011237987, 'constraint'),\n",
            "   (0.009667443, 'bit'),\n",
            "   (0.009407837, 'path'),\n",
            "   (0.008442656, 'solution'),\n",
            "   (0.008111281, 'matching'),\n",
            "   (0.007638281, 'node'),\n",
            "   (0.007575994, 'matrix'),\n",
            "   (0.0072616176, 'match'),\n",
            "   (0.006784121, 'cost'),\n",
            "   (0.0067355908, 'optimization'),\n",
            "   (0.006241798, 'decoding'),\n",
            "   (0.0061817146, 'coding'),\n",
            "   (0.0061640088, 'routing'),\n",
            "   (0.0056452295, 'distance'),\n",
            "   (0.0055263503, 'message'),\n",
            "   (0.0051627755, 'channel'),\n",
            "   (0.0047452115, 'encoding'),\n",
            "   (0.004593615, 'objective')],\n",
            "  -1.968621783902233)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall there are many patterns that are similar to each other since the topics increase the coherence increases"
      ],
      "metadata": {
        "id": "sKNoLGf7Blpf"
      }
    }
  ]
}